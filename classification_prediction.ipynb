{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "# importing needed libraries\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from seaborn_qqplot import pplot\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.impute import  SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"df_train.csv\")\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean columns changed\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SeniorCitizen values changed\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_features = [\"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
    "                    \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smart features imputed\n",
    "df_train[smart_features].isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row with missing Churn value dropped\n",
    "df_train[df_train.Churn.isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaned\n",
    "df_train.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unexpected value in TotalCharges column\n",
    "df_train[df_train[\"TotalCharges\"] == \" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.TotalCharges = pd.to_numeric(df_train.TotalCharges, errors='coerce') #converts \" \" to NaN\n",
    "df_train.TotalCharges = df_train.TotalCharges.fillna(df_train.TotalCharges.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df_train.select_dtypes(exclude=['float', 'int'])\n",
    "print(len(cat_columns.columns))\n",
    "cat_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(cat_columns.columns)\n",
    "cols.remove('Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set up figure and axes\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, sharex=False, sharey=False, figsize=(16, 16))\n",
    "fig.suptitle('Barplots of Categorical Variables', fontsize=16)\n",
    "\n",
    "#flatten axes array to loop through\n",
    "axes = axes.flatten()\n",
    "\n",
    "#access axes and create barplots\n",
    "for i, cat_var  in enumerate(cols):\n",
    "    ax = sns.countplot(data=cat_columns, x=cat_var, ax=axes[i], hue='Churn');\n",
    "    ax.legend().set_visible(False)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "    axes[i].set_title(cat_var)\n",
    "\n",
    "\n",
    "# Add a single legend for all the countplots outside the grid\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=30, ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_variables = []\n",
    "insignificant_variables = []\n",
    "\n",
    "def chi_square_test(var):\n",
    "\n",
    "    # Create a contingency table (cross-tabulation) of the two categorical variables\n",
    "    contingency_table = pd.crosstab(df_train[var], df_train['Churn'])\n",
    "\n",
    "    # Perform the Chi-Square test of independence\n",
    "    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Print the results\n",
    "    print(f'{var}')\n",
    "    print(f\"Chi-Square Test of Independence Results:\")\n",
    "    print(\"Chi-Square Statistic:\", chi2_stat)\n",
    "    print(\"p-value:\", p_value)\n",
    "    print(\"Degrees of Freedom:\", dof)\n",
    "    print(\"Expected Frequencies Table:\")\n",
    "    print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n",
    "\n",
    "    # Interpret the results\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(f\"There is a SIGNIFICANT RELATIONSHIP between {var} and Churn.\")\n",
    "        significant_variables.append(var)\n",
    "    else:\n",
    "        print(f\"There is NO SIGNIFICANT RELATIONSHIP between {var} and Churn.\")\n",
    "        insignificant_variables.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    chi_square_test(var=col)\n",
    "    print(\"****\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Insignificant variables: ', insignificant_variables)\n",
    "print()\n",
    "print('Significant Variables: ')\n",
    "significant_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data = df_train.copy()\n",
    "churn_data.to_csv('churn_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop gender and phone service.\n",
    "df_train = df_train.drop(['gender', 'PhoneService'], axis=1)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split. split data into train and eval set to maintain integrity of test set\n",
    "X = df_train.drop('Churn', axis=1)\n",
    "y = df_train['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)\n",
    "#print(X_train.shape, X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract numerical and categorical features\n",
    "cat_cols = list(X.select_dtypes(include='object').columns)\n",
    "num_cols = list(X.select_dtypes(exclude='object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns\n",
    "X = X[num_cols + cat_cols]\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define preprocessing for categorical features\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore') )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't do any numerical transformations to prevent data leakage before splitting.\n",
    "\n",
    "cat_preprocessor = ColumnTransformer(transformers=[\n",
    "   ('Num_transformer', 'passthrough', num_cols),\n",
    "   ('cat_transformer', cat_transformer, cat_cols)\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prepared = cat_preprocessor.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain transformed cat_cols columns\n",
    "transformed_columns = (num_cols +\n",
    "   list(cat_preprocessor.named_transformers_['cat_transformer'].named_steps['encoder'].get_feature_names_out(cat_cols) ))\n",
    "len(transformed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe\n",
    "X_prepared = pd.DataFrame(X_prepared, columns=transformed_columns)\n",
    "X_prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=99)\n",
    "X_balanced, y_balanced= smote.fit_resample(X_prepared, y)\n",
    "print(X_balanced.shape, y_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "#set stratify=y to ensure minority class is well represented in both sets.\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_balanced, y_balanced, test_size=0.2,\n",
    "                                                    stratify=y_balanced, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape of trainset: ', X_train.shape, y_train.shape)\n",
    "print('shape of evaluation set: ', X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build numerical transformer pipeline after splitting data\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('num_imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "  ])\n",
    "\n",
    "X_train[num_cols] = num_transformer.fit_transform(X_train[num_cols])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=transformed_columns)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model based feature selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=99)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "selector = SelectFromModel(clf, prefit=True)\n",
    "X_train_reducedFeatures = selector.transform(X_train)\n",
    "print('feature reduced train set shape:', X_train_reducedFeatures.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the important features\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the selected feature indices as a boolean mask\n",
    "selected_features_mask = selector.get_support()\n",
    "\n",
    "# Print the names of the selected features\n",
    "selected_feature_names = [feature_names[i] for i, selected in enumerate(selected_features_mask) if selected]\n",
    "print(\"Selected Features:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply feature reduction model transformation\n",
    "X_eval_reducedFeatures = X_eval[selected_feature_names]\n",
    "X_eval_reducedFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape of evaluation set:', X_eval.shape)\n",
    "print('shape of reduced features evaluation set:', X_eval_reducedFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Support vector\": LinearSVC(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "list(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def models_trainer(models_dict, X_train, X_eval, y_train, y_eval):\n",
    "  '''\n",
    "  This function trains a dictionary of models and input train and evaluation sets.\n",
    "\n",
    "  Input parameters Parameters:\n",
    "\n",
    "  models_dict: a dictionary of models to be trained\n",
    "  X_train: train set to be used to train the models\n",
    "  X_eval: evaluation set to be used for evaluating model performance\n",
    "  y_train: train set target\n",
    "  y_eval: evaluation set target label\n",
    "\n",
    "  Output\n",
    "  prints the accuracy, recall, precision and f1_score metrics of each model\n",
    "\n",
    "  '''\n",
    "\n",
    "  #loop through the models\n",
    "  for i in range(len(list(models_dict))):\n",
    "    model = list(models_dict.values())[i]\n",
    "\n",
    "    #train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_eval_pred = model.predict(X_eval)\n",
    "\n",
    "    #evaluation on trainset\n",
    "    train_accuracy_score = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "    train_precision_score = precision_score(y_true=y_train, y_pred=y_train_pred, pos_label='Yes')\n",
    "    train_recall_score = recall_score(y_true=y_train, y_pred=y_train_pred, pos_label='Yes')\n",
    "    train_f1_score = f1_score(y_true=y_train, y_pred=y_train_pred, pos_label='Yes')\n",
    "\n",
    "    #evaluation on eval set.\n",
    "    eval_accuracy_score = accuracy_score(y_true=y_eval, y_pred=y_eval_pred)\n",
    "    eval_precision_score = precision_score(y_true=y_eval, y_pred=y_eval_pred, pos_label='Yes')\n",
    "    eval_recall_score = recall_score(y_true=y_eval, y_pred=y_eval_pred, pos_label='Yes')\n",
    "    eval_f1_score = f1_score(y_true=y_eval, y_pred=y_eval_pred, pos_label='Yes')\n",
    "\n",
    "\n",
    "    print('Model: ', list(models_dict.keys())[i])\n",
    "    print(\"Performance on train set:\")\n",
    "    print(f'Accuracy Score: {train_accuracy_score: .4f}')\n",
    "    print(f'Precision Score: {train_precision_score: .4f}')\n",
    "    print(f'Recall Score: {train_recall_score: .4f}')\n",
    "    print(f'f1 Score: {train_f1_score: .4f}')\n",
    "    print('---'*30)\n",
    "\n",
    "    print(\"Performance on evaluation set:\")\n",
    "    print(f'Accuracy Score: {eval_accuracy_score: .4f}')\n",
    "    print(f'Precision Score: {eval_precision_score: .4f}')\n",
    "    print(f'Recall Score: {eval_recall_score: .4f}')\n",
    "    print(f'f1 Score: {eval_f1_score: .4f}')\n",
    "    print('***' * 30)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation models performance without feature reduction\n",
    "models_trainer(models_dict=models, X_train=X_train, X_eval=X_eval, y_train=y_train, y_eval=y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model with reduced features\n",
    "models_trainer(models_dict=models, X_train=X_train_reducedFeatures, X_eval=X_eval_reducedFeatures, y_train=y_train, y_eval=y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': np.arange(50, 300, 10), # Number of boosting stages to be used\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3], # Learning rate shrinks the contribution of each estimator\n",
    "    'max_depth': np.arange(3, 12, 1), # Maximum depth of the individual estimators\n",
    "    'min_samples_split': np.arange(2, 11, 1), # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': np.arange(1, 11, 1), # Minimum number of samples required to be at a leaf node\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0], # Fraction of samples used for fitting the trees\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None], # Number of features to consider for the best split\n",
    "    'random_state': [99] # Random state for reproducibility\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': np.arange(200, 300, 50),  # Number of trees in the forest\n",
    "    'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "    'max_depth': np.arange(3, 12, 1),  # Maximum depth of the tree\n",
    "    'min_samples_split': np.arange(2, 11, 1),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': np.arange(1, 11, 1),  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],  # Number of features to consider for the best split\n",
    "    'bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "    'random_state': [99]  # Random state for reproducibility\n",
    "}\n",
    "\n",
    "rand_search_models = [('Gradient Boosting', GradientBoostingClassifier(), gb_param_grid),\n",
    "                    ('Random Forest', RandomForestClassifier(), rf_param_grid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best_params = {}\n",
    "best_models = {}\n",
    "best_score = {}\n",
    "\n",
    "for name, model, params in rand_search_models:\n",
    "  random_search = RandomizedSearchCV(estimator=model,\n",
    "                                      param_distributions=params,\n",
    "                                      n_iter=100,\n",
    "                                      cv=3,\n",
    "                                      n_jobs=-1)\n",
    "\n",
    "  random_search.fit(X_train_reducedFeatures, y_train)\n",
    "  model_best_params[name] = random_search.best_params_\n",
    "  best_models[name] = random_search.best_estimator_\n",
    "  best_score[name] = random_search.best_score_\n",
    "\n",
    "for name in model_best_params:\n",
    "  print(f'Best hyperparameters for {name}:')\n",
    "  print(model_best_params[name])\n",
    "  print(f'Best Score for {name}:')\n",
    "  print(best_score[name])\n",
    "  print('***'*30)\n",
    "  print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_gb_classifier = best_models['Gradient Boosting']\n",
    "optimized_rf_classifier = best_models['Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train best model on full trainset\n",
    "optimized_gb_classifier.fit(X_train_reducedFeatures, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred_gb = optimized_gb_classifier.predict(X_eval_reducedFeatures)\n",
    "\n",
    "#evaluate\n",
    "report = classification_report(y_true=y_eval, y_pred=y_pred_gb)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train best model on full trainset\n",
    "optimized_rf_classifier.fit(X_train_reducedFeatures, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred_rf = optimized_rf_classifier.predict(X_eval_reducedFeatures)\n",
    "\n",
    "#evaluate\n",
    "report = classification_report(y_true=y_eval, y_pred=y_pred_rf)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best classifier\n",
    "classifier = optimized_gb_classifier\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_features = list(X.columns)\n",
    "target = 'Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = {'reference_features': reference_features,\n",
    "              'target': target,\n",
    "              'transformed_columns': transformed_columns,\n",
    "              'numerical_columns': num_cols,\n",
    "              'selected_features': selected_feature_names,\n",
    "              'classification_model': classifier}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Replace these with your actual objects\n",
    "model = optimized_gb_classifier  # Replace with your model\n",
    "cat_preprocessor = cat_preprocessor  # Replace with your categorical transformer\n",
    "num_transformer = num_transformer  # Replace with your numerical transformer\n",
    "\n",
    "# Step 2: Save the model and transformers using pickle.dump()\n",
    "# Save the trained model\n",
    "with open('src/optimized_gb_classifier.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "\n",
    "# Save the categorical preprocessor\n",
    "with open('src/cat_preprocessor.pkl', 'wb') as cat_preprocessor_file:\n",
    "    pickle.dump(cat_preprocessor, cat_preprocessor_file)\n",
    "\n",
    "# Save the numerical transformer\n",
    "with open('src/num_transformer.pkl', 'wb') as num_transformer_file:\n",
    "    pickle.dump(num_transformer, num_transformer_file)\n",
    "\n",
    "with open('src/cat_transformer.pkl', 'wb') as num_transformer_file:\n",
    "    pickle.dump(num_transformer, num_transformer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir export/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = os.path.join('.', 'export')\n",
    "destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gradio_toolkit = {\n",
    "    'model': optimized_gb_classifier,\n",
    "    'cat_preprocessor': cat_preprocessor,\n",
    "    'num_transformer': num_transformer,\n",
    "    'cat_transformer': cat_transformer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gradio_toolkit.pkl', 'wb') as toolkit_file:\n",
    "    pickle.dump(gradio_toolkit, toolkit_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save components\n",
    "with open(os.path.join(destination, 'ml.pkl'), 'wb') as file:\n",
    "  pickle.dump(components, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save packages in working environment\n",
    "!pip freeze > export/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert export and it's content to a zip archive\n",
    "!zip -r export.zip export/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded model and it's components\n",
    "with open(os.path.join(destination, 'ml.pkl'), 'rb') as file:\n",
    "  loaded_components = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_components.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack trained model and it's components\n",
    "reference_features = loaded_components['reference_features']\n",
    "target = loaded_components['target']\n",
    "transformed_columns = loaded_components['transformed_columns']\n",
    "numerical_columns = loaded_components['numerical_columns']\n",
    "selected_features = loaded_components['selected_features']\n",
    "classifier = loaded_components['classification_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test set\n",
    "testset = pd.read_excel('Telco-churn-second-2000.xlsx')\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if data meets expection\n",
    "testset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and reformat testset to meet expectation\n",
    "testset['SeniorCitizen'] = testset['SeniorCitizen'].replace({0:'No', 1:'yes'})\n",
    "testset['TotalCharges'] = pd.to_numeric(testset['TotalCharges'], errors='coerce' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now this looks as expected\n",
    "testset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract columns of interest\n",
    "X_test = testset[reference_features]\n",
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess testset\n",
    "\n",
    "#imputing and encoding cat cols\n",
    "X_test_prepared = cat_preprocessor.transform(X_test)\n",
    "print(X_test_prepared.shape)\n",
    "print(type(X_test_prepared))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe using transformed columns\n",
    "X_test_prepared = pd.DataFrame(X_test_prepared, columns=transformed_columns)\n",
    "X_test_prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply numeric transformer\n",
    "X_test_prepared[num_cols] = num_transformer.transform(X_test_prepared[num_cols])\n",
    "X_test_prepared.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select important features\n",
    "X_test_prepared_reducedFeatures = X_test_prepared[selected_feature_names]\n",
    "X_test_prepared_reducedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testset predictions\n",
    "y_pred_testset = classifier.predict(X_test_prepared_reducedFeatures)\n",
    "y_pred_df = pd.DataFrame(y_pred_testset, columns=['Churn'])\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append results to test dataframe\n",
    "results = pd.concat([testset, y_pred_df], axis=1)\n",
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
